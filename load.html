<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Script Tokenizer</title>
<script src="https://unpkg.com/compromise@13.11.3/builds/compromise.min.js"></script>
<style>
body {
  font-family: "Segoe UI", sans-serif;
  background: #f9fafb;
  margin: 0;
  padding: 20px;
  color: #222;
}
h1 { text-align: center; }
#results {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
  gap: 15px;
  margin-top: 20px;
}
.card {
  background: white;
  border-radius: 12px;
  box-shadow: 0 2px 8px rgba(0,0,0,0.1);
  padding: 15px;
  max-height: 400px;
  overflow-y: auto;
}
button {
  background: #2563eb;
  color: white;
  border: none;
  padding: 10px 18px;
  border-radius: 6px;
  cursor: pointer;
  font-size: 15px;
  margin-top: 15px;
}
button:hover { background: #1e40af; }
pre {
  white-space: pre-wrap;
  word-break: break-word;
  font-size: 13px;
  color: #333;
}
</style>
</head>
<body>
<h1>Movie Script Tokenizer</h1>
<p>Fetching and tokenizing movie scripts into parts of speech...</p>

<div id="results"></div>
<div style="text-align:center">
  <button id="downloadBtn">Download JSON</button>
</div>

<script>
const urls = [
  "https://api.allorigins.win/raw?url=http://www.dailyscript.com/scripts/eight-millimeter.html",
  "https://api.allorigins.win/raw?url=http://www.scifiscripts.com/scripts/5thelement.txt",
  "https://api.allorigins.win/raw?url=http://www.awesomefilm.com/script/48hours.txt",
  "https://api.allorigins.win/raw?url=http://www.scifiscripts.com/scripts/2001.txt",
  "https://api.allorigins.win/raw?url=http://www.dailyscript.com/scripts/15minutes.html",
  "https://api.allorigins.win/raw?url=http://www.dailyscript.com/scripts/Alien_Nation_Bannon_Cameron_October_1987.html",
  "https://api.allorigins.win/raw?url=http://www.horrorlair.com/scripts/aliens.html",
  "https://api.allorigins.win/raw?url=http://www.dailyscript.com/scripts/Erik+The+Viking.txt"
];

const allTokens = { noun: [], pronoun: [], adjective: [], adverb: [], verb: [], other: [] };

async function fetchAndTokenize() {
  const resultsDiv = document.getElementById('results');
  for (const link of urls) {
    const card = document.createElement('div');
    card.className = 'card';
    card.innerHTML = `<h3>${link}</h3><pre>Loading...</pre>`;
    resultsDiv.appendChild(card);

    try {
      const res = await fetch(link);
      const text = await res.text();
      const doc = nlp(text);

      const nouns = doc.nouns().out('array');
      const pronouns = doc.pronouns().out('array');
      const adjectives = doc.adjectives().out('array');
      const adverbs = doc.adverbs().out('array');
      const verbs = doc.verbs().out('array');
      const known = [...nouns, ...pronouns, ...adjectives, ...adverbs, ...verbs];
      const allWords = doc.terms().out('array');
      const others = allWords.filter(w => !known.includes(w));

      allTokens.noun.push(...nouns);
      allTokens.pronoun.push(...pronouns);
      allTokens.adjective.push(...adjectives);
      allTokens.adverb.push(...adverbs);
      allTokens.verb.push(...verbs);
      allTokens.other.push(...others);

      card.querySelector('pre').textContent =
        `Nouns: ${nouns.length}\nPronouns: ${pronouns.length}\nAdjectives: ${adjectives.length}\nAdverbs: ${adverbs.length}\nVerbs: ${verbs.length}\nOthers: ${others.length}`;
    } catch (err) {
      card.querySelector('pre').textContent = 'Error fetching: ' + err.message;
    }
  }
}

document.getElementById('downloadBtn').addEventListener('click', () => {
  const blob = new Blob([JSON.stringify(allTokens, null, 2)], { type: "application/json" });
  const a = document.createElement('a');
  a.href = URL.createObjectURL(blob);
  a.download = 'tokens.json';
  a.click();
});

fetchAndTokenize();
</script>
</body>
</html>
